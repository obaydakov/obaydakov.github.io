<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on If you torture the data long enough, it will confess ©</title>
    <link>/post/</link>
    <description>Recent content in Posts on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>4 Python Libraries for Automated Feature Engineering That You Should Use in 2023</title>
      <link>/post/2024-01-13-4-python-libraries-for-automated-feature-engineering-that-you-should-use-in-2023/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-4-python-libraries-for-automated-feature-engineering-that-you-should-use-in-2023/</guid>
      <description>Use these frameworks to empower your machine-learning work
Link</description>
    </item>
    
    <item>
      <title>A Cheat Sheet and Some Recipes For Building Advanced RAG</title>
      <link>/post/2024-01-13-a-cheat-sheet-and-some-recipes-for-building-advanced-rag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-a-cheat-sheet-and-some-recipes-for-building-advanced-rag/</guid>
      <description>The RAG cheat sheet shared above was greatly inspired by a recent RAG survey paper (“Retrieval-Augmented Generation for Large Language Models: A Survey” Gao, Yunfan, et al. 2023).
Link</description>
    </item>
    
    <item>
      <title>Auto-Generated Agent Chat: Revolutionizing Group Conversations with RAG</title>
      <link>/post/2024-01-13-auto-generated-agent-chat-revolutionizing-group-conversations-with-rag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-auto-generated-agent-chat-revolutionizing-group-conversations-with-rag/</guid>
      <description>In the ever-evolving landscape of artificial intelligence (AI) and natural language processing (NLP), researchers and developers continue to push the boundaries of what’s possible. One such groundbreaking development is the Auto Generated Agent Chat, a cutting-edge system that employs Retrieval Augmented Generation (RAG) to transform group conversations. This technology combines the strengths of both retrieval-based and generative models, offering a unique and efficient solution for enhancing communication in group settings.</description>
    </item>
    
    <item>
      <title>Build a Conversational RAG with Mistral-7B and LangChain </title>
      <link>/post/2024-01-13-build-a-conversational-rag-with-mistral-7b-and-langchain/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-build-a-conversational-rag-with-mistral-7b-and-langchain/</guid>
      <description>How to store the conversation history in memory and include it within our prompt. How to transform the input question such that it retrieves the relevant information from our vector database.
Link</description>
    </item>
    
    <item>
      <title>Function Calling Is Also Available for Open Source LLMs in AutoGen</title>
      <link>/post/2024-01-13-function-calling-is-also-available-for-open-source-llms-in-autogen/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-function-calling-is-also-available-for-open-source-llms-in-autogen/</guid>
      <description>In this tutorial, I am going to keep developing multi-agent LLM applications in the AutoGen framework and using decent open-source language models with function calls to see whether they can generate and execute a function task like calculation for currency exchange.
Link</description>
    </item>
    
    <item>
      <title>Hosting Multiple LLMs on a Single Endpoint - AWS SageMaker</title>
      <link>/post/2024-01-13-hosting-multiple-llms-on-a-single-endpoint-aws-sagemaker/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-hosting-multiple-llms-on-a-single-endpoint-aws-sagemaker/</guid>
      <description>Utilize SageMaker Inference Components to Host Flan &amp;amp; Falcon in a Cost &amp;amp; Performance Efficient Manner
Link</description>
    </item>
    
    <item>
      <title>How to Web Scrape Wikipedia with LLM Agents</title>
      <link>/post/2024-01-13-how-to-web-scrape-wikipedia-with-llm-agents/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-how-to-web-scrape-wikipedia-with-llm-agents/</guid>
      <description>Simple guide to using LangChain Agents and Tools with OpenAI’s LLMs and Function Calling for web scraping of Wikipedia
Link</description>
    </item>
    
    <item>
      <title>Intelligent Graph = Knowledge Graph &#43; Intelligent Agents</title>
      <link>/post/2024-01-13-intelligent-graph-knowledge-graph-intelligent-agents/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-intelligent-graph-knowledge-graph-intelligent-agents/</guid>
      <description>The IntelligentGraph capability is when intelligent agents can be embedded in an RDF graph. These agents are activated only when the graph is queried for results referencing the agent.
Link</description>
    </item>
    
    <item>
      <title>LlamaIndex - Building a Custom Agent</title>
      <link>/post/2024-01-13-llamaindex-building-a-custom-agent/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-llamaindex-building-a-custom-agent/</guid>
      <description>We show you how to build a simple agent that adds a retry layer on top of a RouterQueryEngine, allowing it to retry queries until the task is complete. We build this on top of both a SQL tool and a vector index query tool. Even if the tool makes an error or only answers part of the question, the agent can continue retrying the question until the task is complete.</description>
    </item>
    
    <item>
      <title>LLM Agents — Intuitively and Exhaustively Explained</title>
      <link>/post/2024-01-13-llm-agents-intuitively-and-exhaustively-explained/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-llm-agents-intuitively-and-exhaustively-explained/</guid>
      <description>Empowering Language Models to Reason and Act
Link</description>
    </item>
    
    <item>
      <title>LLMCompiler: An LLM Compiler for Parallel Function Calling</title>
      <link>/post/2024-01-13-llmcompiler-an-llm-compiler-for-parallel-function-calling/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-llmcompiler-an-llm-compiler-for-parallel-function-calling/</guid>
      <description>LLMCompiler is a framework that enables an efficient and effective orchestration of parallel function calling with LLMs, including both open-source and close-source models, by automatically identifying which tasks can be performed in parallel and which ones are interdependent.
[Link]{https://github.com/SqueezeAILab/LLMCompiler}
LLM Compiler Agent Cookbook</description>
    </item>
    
    <item>
      <title>Multi-Document AutoRetrieval (with Weaviate) Pack</title>
      <link>/post/2024-01-13-multi-document-autoretrieval-with-weaviate-pack/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-multi-document-autoretrieval-with-weaviate-pack/</guid>
      <description>This LlamaPack implements structured hierarchical retrieval over multiple documents, using multiple @weaviate_io collections.
Link</description>
    </item>
    
    <item>
      <title>Optimizing RAG Systems with LlamaIndex: Strategies for Production Performance</title>
      <link>/post/2024-01-13-optimizing-rag-systems-with-llamaindex-strategies-for-production-performance/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-optimizing-rag-systems-with-llamaindex-strategies-for-production-performance/</guid>
      <description>Prototyping a Retrieval-Augmented Generation (RAG) application is relatively straightforward, but the challenge lies in optimizing it for performance, robustness, and scalability across vast knowledge repositories. This guide aims to provide insights, strategies, and implementations leveraging LlamaIndex to enhance the efficiency of your RAG pipeline, catering to complex datasets and ensuring accurate query responses without hallucinations.
Link</description>
    </item>
    
    <item>
      <title>YouTube Transcripts → Knowledge Graphs for RAG Applications</title>
      <link>/post/2024-01-13-youtube-transcripts-knowledge-graphs-for-rag-applications/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-youtube-transcripts-knowledge-graphs-for-rag-applications/</guid>
      <description>Here we will explore how to scrape YouTube video transcripts into a knowledge graph for Retrieval Augmented Generation (RAG) applications. We will use Google Cloud Platform to store our initial transcripts, LangChain to create documents from the transcripts and a Neo4j graph database to store the resulting documents. In this example we will be creating a knowledge graph containing objective musical facts spoken by Anthony Fantano himself on a select few music genres.</description>
    </item>
    
    <item>
      <title>Autonomous GPT-4: From ChatGPT to AutoGPT, AgentGPT, BabyAGI, HuggingGPT, and Beyond</title>
      <link>/post/2023-07-23-autonomous-gpt-4-from-chatgpt-to-autogpt-agentgpt-babyagi-hugginggpt-and-beyond/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-07-23-autonomous-gpt-4-from-chatgpt-to-autogpt-agentgpt-babyagi-hugginggpt-and-beyond/</guid>
      <description>Emerging task automation and AI agents with GPT-4 after LangChain and LlamaIndex integration trend
Link</description>
    </item>
    
    <item>
      <title>Building and Managing an Isolation Forest Anomaly Detection Pipeline with Kedro</title>
      <link>/post/2023-07-23-building-and-managing-an-isolation-forest-anomaly-detection-pipeline-with-kedro/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-07-23-building-and-managing-an-isolation-forest-anomaly-detection-pipeline-with-kedro/</guid>
      <description>Anomaly (fraud) detection pipeline on credit card transaction data using Isolation Forest machine learning model and Kedro framework
Link</description>
    </item>
    
    <item>
      <title>Building LLM applications for production</title>
      <link>/post/2023-07-23-building-llm-applications-for-production/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-07-23-building-llm-applications-for-production/</guid>
      <description>Building LLM applications for production
Link</description>
    </item>
    
    <item>
      <title>Creating GPT-Driven Applications Using LangChain</title>
      <link>/post/2023-07-23-creating-gpt-driven-applications-using-langchain/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-07-23-creating-gpt-driven-applications-using-langchain/</guid>
      <description>Large Language Models (LLMs) like OpenAI ChatGPT are called foundational models because even though they are trained for a relatively small set of tasks, they work exceptionally well for multiple unseen downstream tasks. While there is still some debate on how they are so good, at a high level it is quite easy to under what they do — they just predict the next word (read tokens). And all the cool tools you see built using these models, are nothing but the smart application of this feature.</description>
    </item>
    
    <item>
      <title>Extract Insights from Text Data inside Databases using OpenAI GPT-3 and MindsDB integration</title>
      <link>/post/2023-07-23-extract-insights-from-text-data-inside-databases-using-openai-gpt-3-and-mindsdb-integration/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-07-23-extract-insights-from-text-data-inside-databases-using-openai-gpt-3-and-mindsdb-integration/</guid>
      <description>Imagine you have a lot of text data inside your database. And you want to extract insights to analyze it or perform various AI tasks on text data. In this article, you will learn how to use MindsDB to integrate your database with OpenAI GPT-3 and get insights from all your text data at once with a few SQL commands instead of making multiple individual API calls, ETL-ing and moving massive amounts of data.</description>
    </item>
    
    <item>
      <title>Finance NLP 1.5.0 is out!</title>
      <link>/post/2023-07-23-finance-nlp-1-5-0-is-out/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-07-23-finance-nlp-1-5-0-is-out/</guid>
      <description>Finance NLP is a John Snow Lab’s product, launched 2022 to provide state-of-the-art, autoscalable, domain-specific NLP on top of Spark. With more than 100 models, featuring Deep Learning and Transformer-based architectures
Link</description>
    </item>
    
  </channel>
</rss>
