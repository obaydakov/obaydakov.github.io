<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on If you torture the data long enough, it will confess ©</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 14 Nov 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Developing and Deploying a Machine Learning Model on Vertex AI using Python</title>
      <link>/post/2021-11-14-developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-11-14-developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python/</guid>
      <description>&lt;p&gt;Write ML Pipelines that will make your MLOps team happy: follow a clean separation of responsibility between model code and ops code. This article show you how to do that.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python-865b535814f8&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugging Face Transformer Inference Under 1 Millisecond Latency</title>
      <link>/post/2021-11-14-hugging-face-transformer-inference-under-1-millisecond-latency/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-11-14-hugging-face-transformer-inference-under-1-millisecond-latency/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/hugging-face-transformer-inference-under-1-millisecond-latency-e1be0057a51c&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss> 
