<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>datascienceblog.net: R for Data Science on If you torture the data long enough, it will confess ©</title>
    <link>/</link>
    <description>Recent content in datascienceblog.net: R for Data Science on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>4 Python Libraries for Automated Feature Engineering That You Should Use in 2023</title>
      <link>/post/2024-01-13-4-python-libraries-for-automated-feature-engineering-that-you-should-use-in-2023/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-4-python-libraries-for-automated-feature-engineering-that-you-should-use-in-2023/</guid>
      <description>Use these frameworks to empower your machine-learning work
Link</description>
    </item>
    
    <item>
      <title>A Cheat Sheet and Some Recipes For Building Advanced RAG</title>
      <link>/post/2024-01-13-a-cheat-sheet-and-some-recipes-for-building-advanced-rag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-a-cheat-sheet-and-some-recipes-for-building-advanced-rag/</guid>
      <description>The RAG cheat sheet shared above was greatly inspired by a recent RAG survey paper (“Retrieval-Augmented Generation for Large Language Models: A Survey” Gao, Yunfan, et al. 2023).
Link</description>
    </item>
    
    <item>
      <title>Applying OpenAI&#39;s RAG Strategies</title>
      <link>/post/2024-01-13-applying-openai-s-rag-strategies/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-applying-openai-s-rag-strategies/</guid>
      <description>At their demo day, Open AI reported a series of RAG experiments for a customer that they worked with. While evaluation metics will depend on your specific application, it’s interesting to see what worked and what didn&amp;rsquo;t for them. Below, we expand on each method mention and show how you can implement each one for yourself. The ability to understand and these methods on your application is critical: from talking to many partners and users, there is no &amp;ldquo;one-size-fits-all&amp;rdquo; solution because different problems require different retrieval techniques.</description>
    </item>
    
    <item>
      <title>Auto-Generated Agent Chat: Revolutionizing Group Conversations with RAG</title>
      <link>/post/2024-01-13-auto-generated-agent-chat-revolutionizing-group-conversations-with-rag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-auto-generated-agent-chat-revolutionizing-group-conversations-with-rag/</guid>
      <description>In the ever-evolving landscape of artificial intelligence (AI) and natural language processing (NLP), researchers and developers continue to push the boundaries of what’s possible. One such groundbreaking development is the Auto Generated Agent Chat, a cutting-edge system that employs Retrieval Augmented Generation (RAG) to transform group conversations. This technology combines the strengths of both retrieval-based and generative models, offering a unique and efficient solution for enhancing communication in group settings.</description>
    </item>
    
    <item>
      <title>Awesome-LLM</title>
      <link>/post/2024-01-13-awesome-llm/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-awesome-llm/</guid>
      <description>Large Language Models(LLM) have taken the NLP community AI community the Whole World by storm. Here is a curated list of papers about large language models, especially relating to ChatGPT. It also contains frameworks for LLM training, tools to deploy LLM, courses and tutorials about LLM and all publicly available LLM checkpoints and APIs.
Link</description>
    </item>
    
    <item>
      <title>Best LLM and LLMOps Resources for 2023</title>
      <link>/post/2024-01-13-best-llm-and-llmops-resources-for-2023/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-best-llm-and-llmops-resources-for-2023/</guid>
      <description>Curated list of best courses, books, resources on large language model
Link</description>
    </item>
    
    <item>
      <title>Beyond Basic Chatbots: How Semantic Router is Changing the Game</title>
      <link>/post/2024-01-13-beyond-basic-chatbots-how-semantic-router-is-changing-the-game/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-beyond-basic-chatbots-how-semantic-router-is-changing-the-game/</guid>
      <description>A Semantic Router is an advanced layer in the realm of chatbots and natural language processing. Think of it as a fuzzy yet deterministic interface layered over your chatbots or any system that processes natural language. Its primary function? To serve as a super-fast decision-making layer for Large Language Models (LLMs).
Link</description>
    </item>
    
    <item>
      <title>Build a Conversational RAG with Mistral-7B and LangChain </title>
      <link>/post/2024-01-13-build-a-conversational-rag-with-mistral-7b-and-langchain/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-build-a-conversational-rag-with-mistral-7b-and-langchain/</guid>
      <description>How to store the conversation history in memory and include it within our prompt. How to transform the input question such that it retrieves the relevant information from our vector database.
Link</description>
    </item>
    
    <item>
      <title>Building LLM Agents in 3 Levels of Complexity: From Scratch, OpenAI Functions &amp; LangChain</title>
      <link>/post/2024-01-13-building-llm-agents-in-3-levels-of-complexity-from-scratch-openai-functions-langchain/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-building-llm-agents-in-3-levels-of-complexity-from-scratch-openai-functions-langchain/</guid>
      <description>Understanding how LLM agents work by building it at 3 levels of complexity
Link</description>
    </item>
    
    <item>
      <title>Constructing an Efficient Knowledge Graph RAG Pipeline with LlamaIndex</title>
      <link>/post/2024-01-13-constructing-an-efficient-knowledge-graph-rag-pipeline-with-llamaindex/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-constructing-an-efficient-knowledge-graph-rag-pipeline-with-llamaindex/</guid>
      <description>Retrieval Augmented Generation (RAG) emerges as a solution to bridge this gap, allowing LLMs to access external knowledge sources. This article delves into RAG, examines its elements, and constructs a usable RAG workflow that harnesses the potential of LlamaIndex, a knowledge graph.
Link</description>
    </item>
    
    <item>
      <title>Eden AI &#43; LangChain</title>
      <link>/post/2024-01-13-eden-ai-langchain/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-eden-ai-langchain/</guid>
      <description>Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website: https://edenai.co/ )
Link
Story Generation
Eden AI x LangChain: Harnessing LLMs, Embeddings, and AI</description>
    </item>
    
    <item>
      <title>Function Calling Is Also Available for Open Source LLMs in AutoGen</title>
      <link>/post/2024-01-13-function-calling-is-also-available-for-open-source-llms-in-autogen/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-function-calling-is-also-available-for-open-source-llms-in-autogen/</guid>
      <description>In this tutorial, I am going to keep developing multi-agent LLM applications in the AutoGen framework and using decent open-source language models with function calls to see whether they can generate and execute a function task like calculation for currency exchange.
Link</description>
    </item>
    
    <item>
      <title>GPT Researcher - Tavily</title>
      <link>/post/2024-01-13-gpt-researcher-tavily/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-gpt-researcher-tavily/</guid>
      <description>The agent can produce detailed, factual and unbiased research reports, with customization options for focusing on relevant resources, outlines, and lessons. Inspired by the recent Plan-and-Solve and RAG papers, GPT Researcher addresses issues of speed, determinism and reliability, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operations.
Link
Building a Tavily Data Agent
research-assistan</description>
    </item>
    
    <item>
      <title>Hosting Multiple LLMs on a Single Endpoint - AWS SageMaker</title>
      <link>/post/2024-01-13-hosting-multiple-llms-on-a-single-endpoint-aws-sagemaker/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-hosting-multiple-llms-on-a-single-endpoint-aws-sagemaker/</guid>
      <description>Utilize SageMaker Inference Components to Host Flan &amp;amp; Falcon in a Cost &amp;amp; Performance Efficient Manner
Link</description>
    </item>
    
    <item>
      <title>How to Web Scrape Wikipedia with LLM Agents</title>
      <link>/post/2024-01-13-how-to-web-scrape-wikipedia-with-llm-agents/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-how-to-web-scrape-wikipedia-with-llm-agents/</guid>
      <description>Simple guide to using LangChain Agents and Tools with OpenAI’s LLMs and Function Calling for web scraping of Wikipedia
Link</description>
    </item>
    
    <item>
      <title>Intelligent Graph = Knowledge Graph &#43; Intelligent Agents</title>
      <link>/post/2024-01-13-intelligent-graph-knowledge-graph-intelligent-agents/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-intelligent-graph-knowledge-graph-intelligent-agents/</guid>
      <description>The IntelligentGraph capability is when intelligent agents can be embedded in an RDF graph. These agents are activated only when the graph is queried for results referencing the agent.
Link</description>
    </item>
    
    <item>
      <title>Intro to LangChain Agents with Semantic Router</title>
      <link>/post/2024-01-13-intro-to-langchain-agents-with-semantic-router/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-intro-to-langchain-agents-with-semantic-router/</guid>
      <description>Use routes to remind agents of particular information or routes (we will do this in this notebook). Use routes to act as protective guardrails against specific types of queries.
Link</description>
    </item>
    
    <item>
      <title>Introducing Query Pipelines</title>
      <link>/post/2024-01-13-introducing-query-pipelines/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-introducing-query-pipelines/</guid>
      <description>Today we introduce Query Pipelines, a new declarative API within LlamaIndex that allows you to concisely orchestrate simple-to-advanced query workflows over your data for different use cases (RAG, structured data extraction, and more).
Link
Usage Pattern</description>
    </item>
    
    <item>
      <title>Langchain &#43; AWS</title>
      <link>/post/2024-01-13-langchain-aws/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-langchain-aws/</guid>
      <description>Langchain + AWS
Langchain + Amazon Textract
Langchain + AWS DynamoDB
Langchain + Bedrock (Knowledge Bases)
Langchain + AWS Lambda</description>
    </item>
    
    <item>
      <title>LangChain cookbook</title>
      <link>/post/2024-01-13-langchain-cookbook/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-langchain-cookbook/</guid>
      <description>Example code for building applications with LangChain, with an emphasis on more applied and end-to-end examples than contained in the main documentation.
Link</description>
    </item>
    
  </channel>
</rss>
