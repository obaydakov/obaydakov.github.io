<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RAG on If you torture the data long enough, it will confess ©</title>
    <link>/tags/rag/</link>
    <description>Recent content in RAG on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Jan 2024 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/rag/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Cheat Sheet and Some Recipes For Building Advanced RAG</title>
      <link>/post/2024-01-13-a-cheat-sheet-and-some-recipes-for-building-advanced-rag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-a-cheat-sheet-and-some-recipes-for-building-advanced-rag/</guid>
      <description>&lt;p&gt;The RAG cheat sheet shared above was greatly inspired by a recent RAG survey paper (“Retrieval-Augmented Generation for Large Language Models: A Survey” Gao, Yunfan, et al. 2023).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Advanced RAG Techniques: an Illustrated Overview</title>
      <link>/post/2024-01-13-advanced-rag-techniques-an-illustrated-overview/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-advanced-rag-techniques-an-illustrated-overview/</guid>
      <description>&lt;p&gt;A comprehensive study of the advanced retrieval augmented generation techniques and algorithms, systemising various approaches. The article comes with a collection of links in my knowledge base referencing various implementations and studies mentioned.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://freedium.cfd/https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Advanced Retrieval with LlamaPacks: Elevating RAG in Fewer Lines of Code!</title>
      <link>/post/2024-01-13-advanced-retrieval-with-llamapacks-elevating-rag-in-fewer-lines-of-code/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-advanced-retrieval-with-llamapacks-elevating-rag-in-fewer-lines-of-code/</guid>
      <description>&lt;p&gt;Auto Merging Retriever Pack and Small-to-big Retrieval Pack provided by LlamaIndex perform the best for this experiment. Read on to see what went down&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://python.plainenglish.io/advanced-retrieval-with-llamapacks-elevating-rag-in-fewer-lines-of-code-5d0497339a3c&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Auto-Generated Agent Chat: Revolutionizing Group Conversations with RAG</title>
      <link>/post/2024-01-13-auto-generated-agent-chat-revolutionizing-group-conversations-with-rag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-auto-generated-agent-chat-revolutionizing-group-conversations-with-rag/</guid>
      <description>&lt;p&gt;In the ever-evolving landscape of artificial intelligence (AI) and natural language processing (NLP), researchers and developers continue to push the boundaries of what’s possible. One such groundbreaking development is the Auto Generated Agent Chat, a cutting-edge system that employs Retrieval Augmented Generation (RAG) to transform group conversations. This technology combines the strengths of both retrieval-based and generative models, offering a unique and efficient solution for enhancing communication in group settings.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ai.plainenglish.io/auto-generated-agent-chat-revolutionizing-group-conversations-with-rag-c86f8528a199&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Beyond Basic Chatbots: How Semantic Router is Changing the Game</title>
      <link>/post/2024-01-13-beyond-basic-chatbots-how-semantic-router-is-changing-the-game/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-beyond-basic-chatbots-how-semantic-router-is-changing-the-game/</guid>
      <description>&lt;p&gt;A Semantic Router is an advanced layer in the realm of chatbots and natural language processing. Think of it as a fuzzy yet deterministic interface layered over your chatbots or any system that processes natural language. Its primary function? To serve as a super-fast decision-making layer for Large Language Models (LLMs).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/ai-insights-cobet/beyond-basic-chatbots-how-semantic-router-is-changing-the-game-783dd959a32d&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build a Conversational RAG with Mistral-7B and LangChain </title>
      <link>/post/2024-01-13-build-a-conversational-rag-with-mistral-7b-and-langchain/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-build-a-conversational-rag-with-mistral-7b-and-langchain/</guid>
      <description>&lt;p&gt;How to store the conversation history in memory and include it within our prompt.
How to transform the input question such that it retrieves the relevant information from our vector database.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@thakermadhav/part-2-build-a-conversational-rag-with-langchain-and-mistral-7b-6a4ebe497185&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Query Pipelines</title>
      <link>/post/2024-01-13-introducing-query-pipelines/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-introducing-query-pipelines/</guid>
      <description>&lt;p&gt;Today we introduce Query Pipelines, a new declarative API within LlamaIndex that allows you to concisely orchestrate simple-to-advanced query workflows over your data for different use cases (RAG, structured data extraction, and more).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.llamaindex.ai/introducing-query-pipelines-025dc2bb0537&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/usage_pattern.html#&#34;&gt;Usage Pattern&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LangChain cookbook</title>
      <link>/post/2024-01-13-langchain-cookbook/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-langchain-cookbook/</guid>
      <description>&lt;p&gt;Example code for building applications with LangChain, with an emphasis on more applied and end-to-end examples than contained in the main documentation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/langchain-ai/langchain/tree/master/cookbook&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mastering Chain Composition with LangChain Expression Language (LCEL) through Mixtral-8x7B-Instruct</title>
      <link>/post/2024-01-13-mastering-chain-composition-with-langchain-expression-language-lcel-through-mixtral-8x7b-instruct/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-mastering-chain-composition-with-langchain-expression-language-lcel-through-mixtral-8x7b-instruct/</guid>
      <description>&lt;p&gt;In the intricate landscape of modern software development, orchestrating complex sequences of actions seamlessly poses a significant challenge. Enter LangChain Expression Language (LCEL), a groundbreaking declarative approach designed to revolutionize the composition of chains within software architecture.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ai.gopubby.com/mastering-chain-composition-with-langchain-expression-language-lcel-2d5041fb0cbd&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Document AutoRetrieval (with Weaviate) Pack</title>
      <link>/post/2024-01-13-multi-document-autoretrieval-with-weaviate-pack/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-multi-document-autoretrieval-with-weaviate-pack/</guid>
      <description>&lt;p&gt;This LlamaPack implements structured hierarchical retrieval over multiple documents, using multiple @weaviate_io collections.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://llamahub.ai/l/llama_packs-multidoc_autoretrieval?from=llama_packs&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimizing RAG Systems with LlamaIndex: Strategies for Production Performance</title>
      <link>/post/2024-01-13-optimizing-rag-systems-with-llamaindex-strategies-for-production-performance/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-optimizing-rag-systems-with-llamaindex-strategies-for-production-performance/</guid>
      <description>&lt;p&gt;Prototyping a Retrieval-Augmented Generation (RAG) application is relatively straightforward, but the challenge lies in optimizing it for performance, robustness, and scalability across vast knowledge repositories. This guide aims to provide insights, strategies, and implementations leveraging LlamaIndex to enhance the efficiency of your RAG pipeline, catering to complex datasets and ensuring accurate query responses without hallucinations.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ai.gopubby.com/optimizing-rag-systems-with-llamaindex-strategies-for-production-performance-98628b00364c&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RAG Pipeline with Query Rewriting</title>
      <link>/post/2024-01-13-rag-pipeline-with-query-rewriting/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-rag-pipeline-with-query-rewriting/</guid>
      <description>&lt;p&gt;Here we chain together a full RAG pipeline consisting of query rewriting, retrieval, reranking, and response synthesis.&lt;/p&gt;
&lt;p&gt;Here we can’t use chain syntax because certain modules depend on multiple inputs (for instance, response synthesis expects both the retrieved nodes and the original question). Instead we’ll construct a DAG explicitly, through add_modules and then add_link.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.llamaindex.ai/en/latest/examples/pipeline/query_pipeline.html#&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Retrieval-Augmented Generation(RAG):Paradigms, Technologies, andTrends</title>
      <link>/post/2024-01-13-retrieval-augmented-generation-rag-paradigms-technologies-andtrends/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-retrieval-augmented-generation-rag-paradigms-technologies-andtrends/</guid>
      <description>&lt;p&gt;Retrieval-Augmented Generation(RAG):Paradigms, Technologies, andTrends&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;file:///C:/Users/ippro/Downloads/RAG_Slide_ENG.pdf&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss> 
