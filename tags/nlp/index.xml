<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nlp on If you torture the data long enough, it will confess ©</title>
    <link>/tags/nlp/</link>
    <description>Recent content in nlp on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Jan 2023 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title> Illustrating Reinforcement Learning from Human Feedback (RLHF)</title>
      <link>/post/2023-01-28-illustrating-reinforcement-learning-from-human-feedback-rlhf/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-illustrating-reinforcement-learning-from-human-feedback-rlhf/</guid>
      <description>&lt;p&gt;Language models have shown impressive capabilities in the past few years by generating diverse and compelling text from human input prompts. However, what makes a &amp;ldquo;good&amp;rdquo; text is inherently hard to define as it is subjective and context dependent. There are many applications such as writing stories where you want creativity, pieces of informative text which should be truthful, or code snippets that we want to be executable.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/rlhf&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lvwerra/trl&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI made easy for developers</title>
      <link>/post/2023-01-28-ai-made-easy-for-developers/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-ai-made-easy-for-developers/</guid>
      <description>&lt;p&gt;Eden AI provides a unique API connected to the best AI engines&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.edenai.co/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/edenai/edenai-apis&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT Telegram Bot: Fast. No daily limits. Special chat modes</title>
      <link>/post/2023-01-28-chatgpt-telegram-bot-fast-no-daily-limits-special-chat-modes/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-chatgpt-telegram-bot-fast-no-daily-limits-special-chat-modes/</guid>
      <description>&lt;p&gt;We all love chat.openai.com, but&amp;hellip;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s TERRIBLY laggy, has daily limits, and is only accessible through an archaic web interface.&lt;/p&gt;
&lt;p&gt;This repo is ChatGPT re-created with GPT-3.5 LLM as Telegram Bot. And it works great.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/karfly/chatgpt_telegram_bot&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>copy.ai</title>
      <link>/post/2023-01-28-copy-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-copy-ai/</guid>
      <description>&lt;p&gt;Say &amp;lsquo;goodbye&amp;rsquo; to the blank page for good&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.copy.ai/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fine Tuning GPT-3: Building a Custom Q&amp;A Bot Using Embeddings</title>
      <link>/post/2023-01-28-fine-tuning-gpt-3-building-a-custom-q-a-bot-using-embeddings/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-fine-tuning-gpt-3-building-a-custom-q-a-bot-using-embeddings/</guid>
      <description>&lt;p&gt;In this guide, we discuss how to fine-tune GPT-3 to create a factual question-and-answer bot based on additional knowledge.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.mlq.ai/fine-tuning-gpt-3-question-answer-bot/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generative Question-Answering with Long-Term Memory</title>
      <link>/post/2023-01-28-generative-question-answering-with-long-term-memory/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-generative-question-answering-with-long-term-memory/</guid>
      <description>&lt;p&gt;Generative AI sparked several “wow” moments in 2022. From generative art tools like OpenAI’s DALL-E 2, Midjourney, and Stable Diffusion, to the next generation of Large Language Models like OpenAI’s GPT-3.5 generation models, BLOOM, and chatbots like LaMDA and ChatGPT.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pinecone.io/learn/openai-gen-qa/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started with GPT-3 vs. Open Source LLMs - LangChain</title>
      <link>/post/2023-01-28-getting-started-with-gpt-3-vs-open-source-llms-langchain/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-getting-started-with-gpt-3-vs-open-source-llms-langchain/</guid>
      <description>&lt;p&gt;LangChain is a popular framework that allows users to quickly build apps and pipelines around Large Language Models. It integrates directly with OpenAI&amp;rsquo;s GPT-3 and GPT-3.5 models and Hugging Face&amp;rsquo;s open-source alternatives like Google&amp;rsquo;s flan-t5 models.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nE2skSRWTTs&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GPT-3 Fine Tuning as a Service: Build Your Own Custom AI</title>
      <link>/post/2023-01-28-gpt-3-fine-tuning-as-a-service-build-your-own-custom-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-gpt-3-fine-tuning-as-a-service-build-your-own-custom-ai/</guid>
      <description>&lt;p&gt;We&amp;rsquo;re excited to announce our new service offering: GPT-3 fine tuning as a service. If you&amp;rsquo;re looking to achieve better results, reduce latency, and save costs on a wide range of natural language processing (NLP) tasks, we&amp;rsquo;re here to help.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.mlq.ai/gpt-3-fine-tuning-as-a-service/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to implement Q&amp;A against your documentation with GPT3, embeddings and Datasette</title>
      <link>/post/2023-01-28-how-to-implement-q-a-against-your-documentation-with-gpt3-embeddings-and-datasette/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-how-to-implement-q-a-against-your-documentation-with-gpt3-embeddings-and-datasette/</guid>
      <description>&lt;p&gt;If you’ve spent any time with GPT-3 or ChatGPT, you’ve likely thought about how useful it would be if you could point them at a specific, current collection of text or documentation and have it use that as part of its input for answering questions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://simonwillison.net/2023/Jan/13/semantic-search-answers/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LIGHTNING TRANSFORMERS</title>
      <link>/post/2023-01-28-lightning-transformers/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-lightning-transformers/</guid>
      <description>&lt;p&gt;LIGHTNING TRANSFORMERS documentation&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lightning-transformers.readthedocs.io/en/latest/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pinecone AI examples</title>
      <link>/post/2023-01-28-pinecone-ai-examples/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-pinecone-ai-examples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/pinecone-io/examples&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.pinecone.io/docs/examples&#34;&gt;Doc examples&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.pinecone.io/docs/quickstart&#34;&gt;Doc quickstart&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pinecone.io/learn/nlp/&#34;&gt;Natural Language Processing (NLP) for Semantic Search&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Question Answering using Embeddings (OpenAI)</title>
      <link>/post/2023-01-28-question-answering-using-embeddings-openai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-question-answering-using-embeddings-openai/</guid>
      <description>&lt;p&gt;Many use cases require GPT-3 to respond to user questions with insightful answers. For example, a customer support chatbot may need to provide answers to common questions. The GPT models have picked up a lot of general knowledge in training, but we often need to ingest and use a large library of more specific information.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/tree/main/examples&#34;&gt;Examples&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>quickchat.ai</title>
      <link>/post/2023-01-28-quickchat-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-quickchat-ai/</guid>
      <description>&lt;p&gt;Quickchat is a human-like AI assistant that provides accurate and instant answers to customer questions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.quickchat.ai/product&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinforcement Learning for tuning language models ( how to train ChatGPT )</title>
      <link>/post/2023-01-28-reinforcement-learning-for-tuning-language-models-how-to-train-chatgpt/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-reinforcement-learning-for-tuning-language-models-how-to-train-chatgpt/</guid>
      <description>&lt;p&gt;The Large Language Model revolution started with the advent of transformers in 2017. Since then there has been an exponential growth in the models trained. Models with 100B+ parameters have been trained. These pre-trained models have changed the way NLP is done. It is much easier to pick a pre-trained model and fine-tune it for a downstream task ( sentiment, question answering, entity recognition etc.. ) than training a model from scratch. Fine-tuning can be done with a much smaller set of examples than training a model from scratch making the whole process of NLP much easier.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@mlblogging.k/reinforcement-learning-for-tuning-language-models-how-chatgpt-is-trained-9ecf23518302&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trudo.ai</title>
      <link>/post/2023-01-28-trudo-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-trudo-ai/</guid>
      <description>&lt;p&gt;Fine tuning NLP models (GPT-3/ChatGPT)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://web.trudo.ai/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oNIHOX_j0qU&#34;&gt;Fine-Tuning GPT-3/ChatGPT and Zapier Integration: A Tutorial for No Code OpenAI Developers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VALL-E</title>
      <link>/post/2023-01-28-vall-e/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-vall-e/</guid>
      <description>&lt;p&gt;An unofficial PyTorch implementation of VALL-E, based on the EnCodec tokenizer.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/enhuiz/vall-e&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Whisper</title>
      <link>/post/2023-01-28-whisper/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-whisper/</guid>
      <description>&lt;p&gt;Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/whisper&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open-Assistant</title>
      <link>/post/2023-01-21-open-assistant/</link>
      <pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-21-open-assistant/</guid>
      <description>&lt;p&gt;We believe that by doing this we will create a revolution in innovation in language. In the same way that stable-diffusion helped the world make art and images in new ways we hope Open Assistant can help improve the world by improving language itself.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/LAION-AI/Open-Assistant&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT CLI and Python Wrapper</title>
      <link>/post/2022-12-10-chatgpt-cli-and-python-wrapper/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-chatgpt-cli-and-python-wrapper/</guid>
      <description>&lt;p&gt;ChatGPT Wrapper is an open-source tool unofficial API that lets you interact with ChatGPT in Python and as a CLI.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mmabrouk/chatgpt-wrapper&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT Telegram Bot</title>
      <link>/post/2022-12-10-chatgpt-telegram-bot/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-chatgpt-telegram-bot/</guid>
      <description>&lt;p&gt;This is a Telegram bot that lets you chat with the chatGPT language model using your local browser. The bot uses Playwright to run chatGPT in Chromium, and can parse code and text, as well as send messages. It also includes a /draw command that allows you to generate pictures using stable diffusion. More features are coming soon.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/altryne/chatGPT-telegram-bot&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I Used ChatGPT to Create an Entire AI Application on AWS</title>
      <link>/post/2022-12-10-i-used-chatgpt-to-create-an-entire-ai-application-on-aws/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-i-used-chatgpt-to-create-an-entire-ai-application-on-aws/</guid>
      <description>&lt;p&gt;This new language model could be the pair programmer of your choice going forward&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/i-used-chatgpt-to-create-an-entire-ai-application-on-aws-5b90e34c3d50&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Probabilistic Time Series Forecasting with Transformers</title>
      <link>/post/2022-12-10-probabilistic-time-series-forecasting-with-transformers/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-probabilistic-time-series-forecasting-with-transformers/</guid>
      <description>&lt;p&gt;Time series forecasting is an essential scientific and business problem and as such has also seen a lot of innovation recently with the use of deep learning based models in addition to the classical methods. An important difference between classical methods like ARIMA and novel deep learning methods is the following.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/time-series-transformers&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Text-to-Image: Diffusion, Text Conditioning, Guidance, Latent Space</title>
      <link>/post/2022-12-10-text-to-image-diffusion-text-conditioning-guidance-latent-space/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-text-to-image-diffusion-text-conditioning-guidance-latent-space/</guid>
      <description>&lt;p&gt;Text-to-image has advanced at a breathless pace in 2021 - 2022, starting with DALL·E, then DALL·E 2, Imagen, and now Stable Diffusion. I dug into a couple of papers to learn more about the space and organized my understanding into a few key concepts&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://eugeneyan.com/writing/text-to-image/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>12 Most Popular NLP Projects of 2022 So Far</title>
      <link>/post/2022-09-25-12-most-popular-nlp-projects-of-2022-so-far/</link>
      <pubDate>Sun, 25 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-09-25-12-most-popular-nlp-projects-of-2022-so-far/</guid>
      <description>&lt;p&gt;Natural Language Processing remains one of the hottest topics of 2022. By using GitHub stars (albeit certainly not the only measure) as a proxy for popularity, we took a look at what NLP projects are getting the most traction so far this year, just as we recently did with machine learning projects. It’s a list with some familiar names but there are plenty of surprises also!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://odsc.com/blog/12-most-popular-nlp-projects-of-2022-so-far/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Skops</title>
      <link>/post/2022-09-03-introducing-skops/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-09-03-introducing-skops/</guid>
      <description>&lt;p&gt;At Hugging Face, we are working on tackling various problems in open-source machine learning, including, hosting models securely and openly, enabling reproducibility, explainability and collaboration. 
We are thrilled to introduce you to our new library: Skops! With Skops, you can host your scikit-learn models on the Hugging Face Hub, create model cards for model documentation and collaborate with others.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/skops&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CS25 I Stanford Seminar</title>
      <link>/post/2022-07-24-cs25-i-stanford-seminar/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-07-24-cs25-i-stanford-seminar/</guid>
      <description>&lt;p&gt;Since their introduction in 2017, transformers have revolutionized Natural Language Processing (NLP). Now, transformers are finding applications all over Deep Learning, be it computer vision (CV), reinforcement learning (RL), Generative Adversarial Networks (GANs), Speech or even Biology. Among other things, transformers have enabled the creation of powerful language models like GPT-3 and were instrumental in DeepMind&amp;rsquo;s recent AlphaFold2, that tackles protein folding.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CS224N: Natural Language Processing with Deep Learning | Winter 2021</title>
      <link>/post/2022-05-02-cs224n-natural-language-processing-with-deep-learning-winter-2021/</link>
      <pubDate>Mon, 02 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-05-02-cs224n-natural-language-processing-with-deep-learning-winter-2021/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugging Face Transformers Amazon SageMaker Examples</title>
      <link>/post/2022-05-02-hugging-face-transformers-amazon-sagemaker-examples/</link>
      <pubDate>Mon, 02 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-05-02-hugging-face-transformers-amazon-sagemaker-examples/</guid>
      <description>&lt;p&gt;Example Jupyter notebooks that demonstrate how to build, train, and deploy Hugging Face Transformers using Amazon SageMaker and the Amazon SageMaker Python SDK.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/huggingface/notebooks/tree/main/sagemaker&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Asking the Right Questions: Training a T5 Transformer Model on a New task</title>
      <link>/post/2022-04-09-asking-the-right-questions-training-a-t5-transformer-model-on-a-new-task/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-asking-the-right-questions-training-a-t5-transformer-model-on-a-new-task/</guid>
      <description>&lt;p&gt;The T5 Transformer frames any NLP task as a text-to-text task enabling pre-trained models to easily learn new tasks. Let’s teach the old dog a new trick!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/asking-the-right-questions-training-a-t5-transformer-model-on-a-new-task-691ebba2d72c&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conversational AI Chatbot with Transformers in Python</title>
      <link>/post/2022-04-09-conversational-ai-chatbot-with-transformers-in-python/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-conversational-ai-chatbot-with-transformers-in-python/</guid>
      <description>&lt;p&gt;Learn how to use Huggingface transformers library to generate conversational responses with the pretrained DialoGPT model in Python.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.thepythoncode.com/article/conversational-ai-chatbot-with-huggingface-transformers-in-python&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conversational Chatbot using Transformers and Streamlit</title>
      <link>/post/2022-04-09-conversational-chatbot-using-transformers-and-streamlit/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-conversational-chatbot-using-transformers-and-streamlit/</guid>
      <description>&lt;p&gt;In this article, we are going to build a Conversational Chatbot app using Transformer (microsoft/DialoGPT-medium model), streamlit.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://chatbotslife.com/conversational-chatbot-using-transformers-and-streamlit-73d621afde9&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two minutes NLP — Quick Introduction to Haystack</title>
      <link>/post/2022-04-09-two-minutes-nlp-quick-introduction-to-haystack/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-two-minutes-nlp-quick-introduction-to-haystack/</guid>
      <description>&lt;p&gt;Question Answering, Semantic Search, and the Retriever-Reader pipeline&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/nlplanet/two-minutes-nlp-quick-introduction-to-haystack-da86d0402998&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/deepset-ai/haystack/issues/486&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deepchecks Suite </title>
      <link>/post/2022-03-21-deepchecks-suite/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-deepchecks-suite/</guid>
      <description>&lt;p&gt;Deepchecks is the leading tool for validating your machine learning models and data, and it enables doing so with minimal effort. Deepchecks accompanies you through various validation needs such as verifying your data’s integrity, inspecting its distributions, validating data splits, evaluating your model and comparing between different models.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.deepchecks.com/en/stable/examples/guides/quickstart_in_5_minutes.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started with Streamlit for NLP</title>
      <link>/post/2022-03-21-getting-started-with-streamlit-for-nlp/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-getting-started-with-streamlit-for-nlp/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/getting-started-with-streamlit-for-nlp-75fe463821ec&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simplifying Transformer Research with xFormers &amp; Lightning</title>
      <link>/post/2022-03-21-simplifying-transformer-research-with-xformers-lightning/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-simplifying-transformer-research-with-xformers-lightning/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://devblog.pytorchlightning.ai/part-i-simplifying-transformer-research-with-xformers-lightning-a715737b8ad4&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual Guide to Transformer Neural Networks</title>
      <link>/post/2022-03-21-visual-guide-to-transformer-neural-networks/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-visual-guide-to-transformer-neural-networks/</guid>
      <description>&lt;p&gt;Visual Guide to Transformer Neural Networks (Series) - Step by Step Intuitive Explanation&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gJ9kaJsE78k&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Flask Web App for Automatic Text Summarization Using SBERT</title>
      <link>/post/2022-02-27-a-flask-web-app-for-automatic-text-summarization-using-sbert/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-02-27-a-flask-web-app-for-automatic-text-summarization-using-sbert/</guid>
      <description>&lt;p&gt;In this blog, we will build a Flask web app that can input any long piece of information such as a blog or news article and summarize it into just five lines!&lt;/p&gt;
&lt;p&gt;Text summarization is an NLP(Natural Language Processing) task. SBERT(Sentence-BERT) has been used to achieve the same.&lt;/p&gt;
&lt;p&gt;By the end of the article, you will learn how to integrate AI models and specifically pre-trained BERT models with Flask web technology as well! I will be explaining the step-by-step implementation right from the setup.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2022/02/a-flask-web-app-for-automatic-text-summarization-using-sbert/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Knowledge Graph for Job Search Using BERT</title>
      <link>/post/2021-12-04-building-a-knowledge-graph-for-job-search-using-bert/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-building-a-knowledge-graph-for-job-search-using-bert/</guid>
      <description>&lt;p&gt;In this tutorial, we will build a job recommendation and skill discovery script that will take unstructured text as input, and will then output job recommendations and skill suggestions based on entities such as skills, years of experience, diploma, and major.&lt;/p&gt;
&lt;p&gt;We will extract entities and relations from job descriptions using the BERT model and we will attempt to build a knowledge graph from skills and years of experience.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/06/knowledge-graph-job-search-bert.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Build a Knowledge Graph with Neo4J and Transformers</title>
      <link>/post/2021-12-04-how-to-build-a-knowledge-graph-with-neo4j-and-transformers/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-how-to-build-a-knowledge-graph-with-neo4j-and-transformers/</guid>
      <description>&lt;p&gt;How to build a knowledge graph from job descriptions using fine-tuned transformer-based Named Entity Recognition (NER) and spacy’s relation extraction models. The method described here can be used in any different field such as biomedical, finance, healthcare, etc.&lt;/p&gt;
&lt;p&gt;Below are the steps we are going to take:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Load our fine-tuned transformer NER and spacy relation extraction model in google colab&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Neo4j Sandbox and add our entities and relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Query our graph to find the highest job match to a target resume, find the three most popular skills and highest skills co-occurrence&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/11/build-knowledge-graph-neo4j-transformers.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Create and Deploy a Simple Sentiment Analysis App via API</title>
      <link>/post/2021-12-04-how-to-create-and-deploy-a-simple-sentiment-analysis-app-via-api/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-how-to-create-and-deploy-a-simple-sentiment-analysis-app-via-api/</guid>
      <description>&lt;p&gt;FastAPI might be able to help. FastAPI is FastAPI is a web framework for building APIs with Python. We will use FastAPI in this article to build a REST API to service an NLP model which can be queried via GET request and can dole out responses to those queries.&lt;/p&gt;
&lt;p&gt;For this example, we will skip the building of our own model, and instead leverage the Pipeline class of the HuggingFace Transformers library. Transformers is full of SOTA NLP models which can be used out of the box as-is, as well as fine-tuned for specific uses and high performance. The library&amp;rsquo;s pipelines can be summed up as:&lt;/p&gt;
&lt;p&gt;The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering.&lt;/p&gt;
&lt;p&gt;Using the Transformers library, FastAPI, and astonishingly little code, we are going to create and deploy a very simple sentiment analysis app. We will also see how extending this same approach to a more complex app would be quite straightforward.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/06/create-deploy-sentiment-analysis-app-api.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Visual Guide to Using BERT for the First Time</title>
      <link>/post/2021-11-14-a-visual-guide-to-using-bert-for-the-first-time/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-11-14-a-visual-guide-to-using-bert-for-the-first-time/</guid>
      <description>&lt;p&gt;This post is a simple tutorial for how to use a variant of BERT to classify sentences.&lt;/p&gt;
&lt;p&gt;This is an example that is basic enough as a first intro, yet advanced enough to showcase some of the key concepts involved.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to fine-tune BERT to classify your Slack chats without coding</title>
      <link>/post/2021-11-14-how-to-fine-tune-bert-to-classify-your-slack-chats-without-coding/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-11-14-how-to-fine-tune-bert-to-classify-your-slack-chats-without-coding/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;images/lifecycle.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Slack chats can become messy with time, proving difficult to extract meaningful information.&lt;/p&gt;
&lt;p&gt;In this article, I want to present a quick codeless way of fine-tuning and deploying the commonly used BERT classifier to do conversational analysis.&lt;/p&gt;
&lt;p&gt;We will use that system to extract tasks, facts, and other valuable information from our Slack conversations.&lt;/p&gt;
&lt;p&gt;It could be easily extended for categorizing any other textual data, like support requests, emails, etc.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/how-to-finetune-bert-to-classify-your-slack-chats-without-coding-3a7002936bcf&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss> 
