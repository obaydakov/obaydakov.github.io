<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nlp on If you torture the data long enough, it will confess ©</title>
    <link>/tags/nlp/</link>
    <description>Recent content in nlp on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Mar 2023 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AI for presentation generation</title>
      <link>/post/2023-03-03-ai-for-presentation-generation/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-ai-for-presentation-generation/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.chatba.com/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building the Knowledge Graph</title>
      <link>/post/2023-03-03-building-the-knowledge-graph/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-building-the-knowledge-graph/</guid>
      <description>&lt;p&gt;Building the Knowledge Graph&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jerryjliu/gpt_index/blob/main/examples/knowledge_graph/KnowledgeGraphDemo.ipynb?utm_source=substack&amp;amp;utm_medium=email&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chatbot with custom knowledge base</title>
      <link>/post/2023-03-03-chatbot-with-custom-knowledge-base/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-chatbot-with-custom-knowledge-base/</guid>
      <description>&lt;p&gt;This notebook has all the code you need to create your own chatbot with custom knowledge base using GPT-3.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1PQXcM_jhN6QJ7uTkxvNbxoI54r03uSr3?usp=sharing&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT With Your Docs | Full Tutorial WITH Code Examples</title>
      <link>/post/2023-03-03-chatgpt-with-your-docs-full-tutorial-with-code-examples/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-chatgpt-with-your-docs-full-tutorial-with-code-examples/</guid>
      <description>&lt;p&gt;In this video, we are joined by Harrison Chase, founder of LangChain. LangChain is a popular open source library focused on making it easier to build AI features and applications, specifically focused on integrating GPT and other language models.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kM3DPWO7YV4&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Custom langchain Agent &amp; Tools with memory</title>
      <link>/post/2023-03-03-custom-langchain-agent-tools-with-memory/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-custom-langchain-agent-tools-with-memory/</guid>
      <description>&lt;p&gt;We will build a web app with Streamlit UI which features 4 Python functions as custom Langchain tools. Our agent will also have a short term conversational memory.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NIG8lXk0ULg&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Prompt Alchemy to Prompt Engineering: An Introduction to Analytic Augmentation</title>
      <link>/post/2023-03-03-from-prompt-alchemy-to-prompt-engineering-an-introduction-to-analytic-augmentation/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-from-prompt-alchemy-to-prompt-engineering-an-introduction-to-analytic-augmentation/</guid>
      <description>&lt;p&gt;This article will introduce the concept of analytic augmentation, a prompt engineering metholodogy that can be used to improve the factual results of LLMs and limit hallucinations.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/williamcotton/empirical-philosophy/blob/main/articles/from-prompt-alchemy-to-prompt-engineering-an-introduction-to-analytic-agumentation.md&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to install Unstructured for Langchain Document loaders. Langchain Unstructured tutorial</title>
      <link>/post/2023-03-03-how-to-install-unstructured-for-langchain-document-loaders-langchain-unstructured-tutorial/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-how-to-install-unstructured-for-langchain-document-loaders-langchain-unstructured-tutorial/</guid>
      <description>&lt;p&gt;These installation steps for unstructured enables document loader to work with all regular files like txt, md, py and most importantly PDFs.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=svzd5d1LXGk&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to write an effective GPT-3 prompt</title>
      <link>/post/2023-03-03-how-to-write-an-effective-gpt-3-prompt/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-how-to-write-an-effective-gpt-3-prompt/</guid>
      <description>&lt;p&gt;6 GPT-3 tips for getting the output you&amp;rsquo;re looking for&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zapier.com/blog/gpt-3-prompt/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HugNLP</title>
      <link>/post/2023-03-03-hugnlp/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-hugnlp/</guid>
      <description>&lt;p&gt;HugNLP is a novel development and application library based on Hugging Face for improving the convenience and effectiveness of NLP researchers. The founder and main developer is Jianing Wang. The collaborators (programmers) are Nuo Chen and Qiushi Sun.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wjn1996/hugnlp&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intelligent question-answering and search for user interviews, powered by GPT-3.</title>
      <link>/post/2023-03-03-intelligent-question-answering-and-search-for-user-interviews-powered-by-gpt-3/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-intelligent-question-answering-and-search-for-user-interviews-powered-by-gpt-3/</guid>
      <description>&lt;p&gt;Intelligent question-answering and search for user interviews, powered by GPT-3.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://summ.readthedocs.io/en/latest/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LangChain 101: Agents Overview &#43; Google Searches</title>
      <link>/post/2023-03-03-langchain-101-agents-overview-google-searches/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-langchain-101-agents-overview-google-searches/</guid>
      <description>&lt;p&gt;LangChain 101 Agents Guide - Agents are bots that take action on your behalf. They connect LLMs to the outside world.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Jq9Sf68ozk0&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LangChain 101: Ask Questions On Your Custom (or Private) Files &#43; Chat GPT</title>
      <link>/post/2023-03-03-langchain-101-ask-questions-on-your-custom-or-private-files-chat-gpt/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-langchain-101-ask-questions-on-your-custom-or-private-files-chat-gpt/</guid>
      <description>&lt;p&gt;LangChain 101: Ask Questions On Your Custom (or Private) Files + Chat GPT&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EnT-ZTrcPrg&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open Assistant Inference Backend Development (Hands-On Coding)</title>
      <link>/post/2023-03-03-open-assistant-inference-backend-development-hands-on-coding/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-open-assistant-inference-backend-development-hands-on-coding/</guid>
      <description>&lt;p&gt;Join me as I build streaming inference into the Hugging Face text generation server, going through cuda, python, rust, grpc, websockets, server-sent events, and more&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6OozhhI6U4g&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prompt Engineering Guide</title>
      <link>/post/2023-03-03-prompt-engineering-guide/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-prompt-engineering-guide/</guid>
      <description>&lt;p&gt;Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs). Researchers use prompt engineering to improve the capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning. Developers use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other tools.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dair-ai/Prompt-Engineering-Guide&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use the Dust Platform to design and deploy Large Language Model apps.</title>
      <link>/post/2023-03-03-use-the-dust-platform-to-design-and-deploy-large-language-model-apps/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-03-03-use-the-dust-platform-to-design-and-deploy-large-language-model-apps/</guid>
      <description>&lt;p&gt;Dust apps rely on model providers to interact with large language models. You can setup your first model provider by clicking on the Providers pane and setting up the OpenAI provider. You&amp;rsquo;ll need to create an account at OpenAI and retrieve your API key.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.dust.tt/quickstart&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title> OpenAI x Pinecone Q&amp;A app</title>
      <link>/post/2023-02-11-openai-x-pinecone-q-a-app/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-openai-x-pinecone-q-a-app/</guid>
      <description>&lt;p&gt;In this repository we have notebooks and source code used to build the OpenAI x Pinecone Q&amp;amp;A app. You can find more information in our webinar here.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pinecone-io/examples/tree/master/integrations/openai/beyond_search_webinar&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A command-line utility to train and deploy Machine Learning/Deep Learning models on AWS SageMaker in a few simple steps!</title>
      <link>/post/2023-02-11-a-command-line-utility-to-train-and-deploy-machine-learning-deep-learning-models-on-aws-sagemaker-in-a-few-simple-steps/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-a-command-line-utility-to-train-and-deploy-machine-learning-deep-learning-models-on-aws-sagemaker-in-a-few-simple-steps/</guid>
      <description>&lt;p&gt;We&amp;rsquo;ll provide you with some examples of how Sagify can simplify and expedite your ML pipelines. You can train, tune and deploy a Machine Learning on the same day by using Sagify!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://kenza-ai.github.io/sagify/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design and Deploy Large Language Model Apps</title>
      <link>/post/2023-02-11-design-and-deploy-large-language-model-apps/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-design-and-deploy-large-language-model-apps/</guid>
      <description>&lt;p&gt;Built on years of experience working with large language models.
With one goal, help accelerate their deployment.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenAI Cookbook</title>
      <link>/post/2023-02-11-openai-cookbook/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-openai-cookbook/</guid>
      <description>&lt;p&gt;The OpenAI Cookbook shares example code for accomplishing common tasks with the OpenAI API.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenAI v2 Embedding &#43; Search &#43; Context enhanced completions</title>
      <link>/post/2023-02-11-openai-v2-embedding-search-context-enhanced-completions/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-openai-v2-embedding-search-context-enhanced-completions/</guid>
      <description>&lt;p&gt;OpenAI v2 Embedding + Search + Context enhanced completions&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpsConfig/OpenAI_Lab&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The missing frontend for GPT-3</title>
      <link>/post/2023-02-11-the-missing-frontend-for-gpt-3/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-the-missing-frontend-for-gpt-3/</guid>
      <description>&lt;p&gt;Build GPT-3 powered apps, without writing any code&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://retune.so/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using AI to Identify Ingredients and Suggest Recipes</title>
      <link>/post/2023-02-11-using-ai-to-identify-ingredients-and-suggest-recipes/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-11-using-ai-to-identify-ingredients-and-suggest-recipes/</guid>
      <description>&lt;p&gt;Sous-chef.ai allows users to take photos of ingredients in their fridge/pantry and ask for a user’s food preferences. Using this information, the app provides customized suggested recipes.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@brh373/using-ai-to-identify-ingredients-and-suggest-recipes-95482e2aca7d&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>awesome-nlp</title>
      <link>/post/2023-02-04-awesome-nlp/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-awesome-nlp/</guid>
      <description>&lt;p&gt;A curated list of resources dedicated to Natural Language Processing&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/keon/awesome-nlp#python&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build a GitHub support bot with GPT3, LangChain, and Python</title>
      <link>/post/2023-02-04-build-a-github-support-bot-with-gpt3-langchain-and-python/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-build-a-github-support-bot-with-gpt3-langchain-and-python/</guid>
      <description>&lt;p&gt;ChatGPT came out a few months ago and blew everyones’ minds with its ability to answer questions sourced from a broad set of knowledge. Around the time that ChatGPT was demonstrating how powerful large language models could be, the Dagster core team was facing a problem.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dagster.io/blog/chatgpt-langchain&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Analysis with ChatGPT and Jupyter Notebooks</title>
      <link>/post/2023-02-04-data-analysis-with-chatgpt-and-jupyter-notebooks/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-data-analysis-with-chatgpt-and-jupyter-notebooks/</guid>
      <description>&lt;p&gt;The conversational way of generating code with ChatGPT works well with the cell structure of Jupyter Notebooks&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/codefile/data-analysis-with-chatgpt-and-jupyter-notebooks-fa2b03753396&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GPT-3 Voice AI Chatbot in Python</title>
      <link>/post/2023-02-04-gpt-3-voice-ai-chatbot-in-python/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-gpt-3-voice-ai-chatbot-in-python/</guid>
      <description>&lt;p&gt;GPT-3 Voice AI Chatbot in Python&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ABIlhTCaWmE&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs/edit#gid=1158069878&#34;&gt;Excel&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to replicate ChatGPT with Langchain and GPT-3?</title>
      <link>/post/2023-02-04-how-to-replicate-chatgpt-with-langchain-and-gpt-3/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-how-to-replicate-chatgpt-with-langchain-and-gpt-3/</guid>
      <description>&lt;p&gt;It is well-known that ChatGPT is currently capable of impressive feats. It is likely that many individuals have ideas for utilizing this technology in their own projects. However, it should be noted that ChatGPT does not currently have an official API. Using an unofficial API may result in difficulties.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ahmadrosid.com/blog/langchain-openai-tutorial&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LangChain Hub</title>
      <link>/post/2023-02-04-langchain-hub/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-langchain-hub/</guid>
      <description>&lt;p&gt;Taking inspiration from Hugging Face Hub, LangChainHub is collection of all artifacts useful for working with LangChain primitives such as prompts, chains and agents. The goal of this repository is to be a central resource for sharing and discovering high quality prompts, chains and agents that combine together to form complex LLM applications.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain-hub&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Longterm Chat External Sources</title>
      <link>/post/2023-02-04-longterm-chat-external-sources/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-longterm-chat-external-sources/</guid>
      <description>&lt;p&gt;GPT-3 chatbot with long-term memory and external sources.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/daveshap/LongtermChatExternalSources&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PlotGenerator</title>
      <link>/post/2023-02-04-plotgenerator/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-plotgenerator/</guid>
      <description>&lt;p&gt;From any synopsis, generate a solid plot.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/daveshap/PlotGenerator&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python &amp; GPT3 Tutorial</title>
      <link>/post/2023-02-04-python-gpt3-tutorial/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-python-gpt3-tutorial/</guid>
      <description>&lt;p&gt;Public Hello World to get used to Python and GPT-3&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/daveshap/PythonGPT3Tutorial&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transformer models: an introduction and catalog — 2023 Edition</title>
      <link>/post/2023-02-04-transformer-models-an-introduction-and-catalog-2023-edition/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-transformer-models-an-introduction-and-catalog-2023-edition/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TRL - Transformer Reinforcement Learning</title>
      <link>/post/2023-02-04-trl-transformer-reinforcement-learning/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-trl-transformer-reinforcement-learning/</guid>
      <description>&lt;p&gt;With trl you can train transformer language models with Proximal Policy Optimization (PPO). The library is built on top of the transformers library by 🤗 Hugging Face. Therefore, pre-trained language models can be directly loaded via transformers. At this point most of decoder architectures and encoder-decoder architectures are supported.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lvwerra/trl?utm_source=substack&amp;amp;utm_medium=email&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What Makes a Dialog Agent Useful?</title>
      <link>/post/2023-02-04-what-makes-a-dialog-agent-useful/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-what-makes-a-dialog-agent-useful/</guid>
      <description>&lt;p&gt;The techniques behind ChatGPT: RLHF, IFT, CoT, Red teaming, and more&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/dialog-agents&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a tokenizer with ChatGPT</title>
      <link>/post/2023-02-04-writing-a-tokenizer-with-chatgpt/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-writing-a-tokenizer-with-chatgpt/</guid>
      <description>&lt;p&gt;This morning I decided to test how good ChatGPT is at generating a non-trivial piece of code. I want to write a complete interpreter along the lines of Robert Nystrom’s excellent book Crafting Interpreters.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://tagide.com/education/writing-a-tokenizer-with-chatgpt/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>𝗗𝗦𝗣: Demonstrate–Search–Predict</title>
      <link>/post/2023-02-04-demonstrate-search-predict/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-demonstrate-search-predict/</guid>
      <description>&lt;p&gt;A framework for composing retrieval models and language models into powerful pipelines that tackle knowledge-intensive tasks.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/stanfordnlp/dsp&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title> Illustrating Reinforcement Learning from Human Feedback (RLHF)</title>
      <link>/post/2023-01-28-illustrating-reinforcement-learning-from-human-feedback-rlhf/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-illustrating-reinforcement-learning-from-human-feedback-rlhf/</guid>
      <description>&lt;p&gt;Language models have shown impressive capabilities in the past few years by generating diverse and compelling text from human input prompts. However, what makes a &amp;ldquo;good&amp;rdquo; text is inherently hard to define as it is subjective and context dependent. There are many applications such as writing stories where you want creativity, pieces of informative text which should be truthful, or code snippets that we want to be executable.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/rlhf&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lvwerra/trl&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI made easy for developers</title>
      <link>/post/2023-01-28-ai-made-easy-for-developers/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-ai-made-easy-for-developers/</guid>
      <description>&lt;p&gt;Eden AI provides a unique API connected to the best AI engines&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.edenai.co/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/edenai/edenai-apis&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT Telegram Bot: Fast. No daily limits. Special chat modes</title>
      <link>/post/2023-01-28-chatgpt-telegram-bot-fast-no-daily-limits-special-chat-modes/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-chatgpt-telegram-bot-fast-no-daily-limits-special-chat-modes/</guid>
      <description>&lt;p&gt;We all love chat.openai.com, but&amp;hellip;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s TERRIBLY laggy, has daily limits, and is only accessible through an archaic web interface.&lt;/p&gt;
&lt;p&gt;This repo is ChatGPT re-created with GPT-3.5 LLM as Telegram Bot. And it works great.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/karfly/chatgpt_telegram_bot&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>copy.ai</title>
      <link>/post/2023-01-28-copy-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-copy-ai/</guid>
      <description>&lt;p&gt;Say &amp;lsquo;goodbye&amp;rsquo; to the blank page for good&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.copy.ai/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fine Tuning GPT-3: Building a Custom Q&amp;A Bot Using Embeddings</title>
      <link>/post/2023-01-28-fine-tuning-gpt-3-building-a-custom-q-a-bot-using-embeddings/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-fine-tuning-gpt-3-building-a-custom-q-a-bot-using-embeddings/</guid>
      <description>&lt;p&gt;In this guide, we discuss how to fine-tune GPT-3 to create a factual question-and-answer bot based on additional knowledge.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.mlq.ai/fine-tuning-gpt-3-question-answer-bot/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generative Question-Answering with Long-Term Memory</title>
      <link>/post/2023-01-28-generative-question-answering-with-long-term-memory/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-generative-question-answering-with-long-term-memory/</guid>
      <description>&lt;p&gt;Generative AI sparked several “wow” moments in 2022. From generative art tools like OpenAI’s DALL-E 2, Midjourney, and Stable Diffusion, to the next generation of Large Language Models like OpenAI’s GPT-3.5 generation models, BLOOM, and chatbots like LaMDA and ChatGPT.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pinecone.io/learn/openai-gen-qa/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started with GPT-3 vs. Open Source LLMs - LangChain</title>
      <link>/post/2023-01-28-getting-started-with-gpt-3-vs-open-source-llms-langchain/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-getting-started-with-gpt-3-vs-open-source-llms-langchain/</guid>
      <description>&lt;p&gt;LangChain is a popular framework that allows users to quickly build apps and pipelines around Large Language Models. It integrates directly with OpenAI&amp;rsquo;s GPT-3 and GPT-3.5 models and Hugging Face&amp;rsquo;s open-source alternatives like Google&amp;rsquo;s flan-t5 models.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nE2skSRWTTs&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GPT-3 Fine Tuning as a Service: Build Your Own Custom AI</title>
      <link>/post/2023-01-28-gpt-3-fine-tuning-as-a-service-build-your-own-custom-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-gpt-3-fine-tuning-as-a-service-build-your-own-custom-ai/</guid>
      <description>&lt;p&gt;We&amp;rsquo;re excited to announce our new service offering: GPT-3 fine tuning as a service. If you&amp;rsquo;re looking to achieve better results, reduce latency, and save costs on a wide range of natural language processing (NLP) tasks, we&amp;rsquo;re here to help.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.mlq.ai/gpt-3-fine-tuning-as-a-service/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to implement Q&amp;A against your documentation with GPT3, embeddings and Datasette</title>
      <link>/post/2023-01-28-how-to-implement-q-a-against-your-documentation-with-gpt3-embeddings-and-datasette/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-how-to-implement-q-a-against-your-documentation-with-gpt3-embeddings-and-datasette/</guid>
      <description>&lt;p&gt;If you’ve spent any time with GPT-3 or ChatGPT, you’ve likely thought about how useful it would be if you could point them at a specific, current collection of text or documentation and have it use that as part of its input for answering questions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://simonwillison.net/2023/Jan/13/semantic-search-answers/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LIGHTNING TRANSFORMERS</title>
      <link>/post/2023-01-28-lightning-transformers/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-lightning-transformers/</guid>
      <description>&lt;p&gt;LIGHTNING TRANSFORMERS documentation&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lightning-transformers.readthedocs.io/en/latest/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pinecone AI examples</title>
      <link>/post/2023-01-28-pinecone-ai-examples/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-pinecone-ai-examples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/pinecone-io/examples&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.pinecone.io/docs/examples&#34;&gt;Doc examples&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.pinecone.io/docs/quickstart&#34;&gt;Doc quickstart&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pinecone.io/learn/nlp/&#34;&gt;Natural Language Processing (NLP) for Semantic Search&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Question Answering using Embeddings (OpenAI)</title>
      <link>/post/2023-01-28-question-answering-using-embeddings-openai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-question-answering-using-embeddings-openai/</guid>
      <description>&lt;p&gt;Many use cases require GPT-3 to respond to user questions with insightful answers. For example, a customer support chatbot may need to provide answers to common questions. The GPT models have picked up a lot of general knowledge in training, but we often need to ingest and use a large library of more specific information.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/tree/main/examples&#34;&gt;Examples&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>quickchat.ai</title>
      <link>/post/2023-01-28-quickchat-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-quickchat-ai/</guid>
      <description>&lt;p&gt;Quickchat is a human-like AI assistant that provides accurate and instant answers to customer questions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.quickchat.ai/product&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinforcement Learning for tuning language models ( how to train ChatGPT )</title>
      <link>/post/2023-01-28-reinforcement-learning-for-tuning-language-models-how-to-train-chatgpt/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-reinforcement-learning-for-tuning-language-models-how-to-train-chatgpt/</guid>
      <description>&lt;p&gt;The Large Language Model revolution started with the advent of transformers in 2017. Since then there has been an exponential growth in the models trained. Models with 100B+ parameters have been trained. These pre-trained models have changed the way NLP is done. It is much easier to pick a pre-trained model and fine-tune it for a downstream task ( sentiment, question answering, entity recognition etc.. ) than training a model from scratch. Fine-tuning can be done with a much smaller set of examples than training a model from scratch making the whole process of NLP much easier.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@mlblogging.k/reinforcement-learning-for-tuning-language-models-how-chatgpt-is-trained-9ecf23518302&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trudo.ai</title>
      <link>/post/2023-01-28-trudo-ai/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-trudo-ai/</guid>
      <description>&lt;p&gt;Fine tuning NLP models (GPT-3/ChatGPT)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://web.trudo.ai/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oNIHOX_j0qU&#34;&gt;Fine-Tuning GPT-3/ChatGPT and Zapier Integration: A Tutorial for No Code OpenAI Developers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VALL-E</title>
      <link>/post/2023-01-28-vall-e/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-vall-e/</guid>
      <description>&lt;p&gt;An unofficial PyTorch implementation of VALL-E, based on the EnCodec tokenizer.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/enhuiz/vall-e&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Whisper</title>
      <link>/post/2023-01-28-whisper/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-28-whisper/</guid>
      <description>&lt;p&gt;Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/whisper&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open-Assistant</title>
      <link>/post/2023-01-21-open-assistant/</link>
      <pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-21-open-assistant/</guid>
      <description>&lt;p&gt;We believe that by doing this we will create a revolution in innovation in language. In the same way that stable-diffusion helped the world make art and images in new ways we hope Open Assistant can help improve the world by improving language itself.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/LAION-AI/Open-Assistant&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT CLI and Python Wrapper</title>
      <link>/post/2022-12-10-chatgpt-cli-and-python-wrapper/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-chatgpt-cli-and-python-wrapper/</guid>
      <description>&lt;p&gt;ChatGPT Wrapper is an open-source tool unofficial API that lets you interact with ChatGPT in Python and as a CLI.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mmabrouk/chatgpt-wrapper&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT Telegram Bot</title>
      <link>/post/2022-12-10-chatgpt-telegram-bot/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-chatgpt-telegram-bot/</guid>
      <description>&lt;p&gt;This is a Telegram bot that lets you chat with the chatGPT language model using your local browser. The bot uses Playwright to run chatGPT in Chromium, and can parse code and text, as well as send messages. It also includes a /draw command that allows you to generate pictures using stable diffusion. More features are coming soon.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/altryne/chatGPT-telegram-bot&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I Used ChatGPT to Create an Entire AI Application on AWS</title>
      <link>/post/2022-12-10-i-used-chatgpt-to-create-an-entire-ai-application-on-aws/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-i-used-chatgpt-to-create-an-entire-ai-application-on-aws/</guid>
      <description>&lt;p&gt;This new language model could be the pair programmer of your choice going forward&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/i-used-chatgpt-to-create-an-entire-ai-application-on-aws-5b90e34c3d50&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Probabilistic Time Series Forecasting with Transformers</title>
      <link>/post/2022-12-10-probabilistic-time-series-forecasting-with-transformers/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-probabilistic-time-series-forecasting-with-transformers/</guid>
      <description>&lt;p&gt;Time series forecasting is an essential scientific and business problem and as such has also seen a lot of innovation recently with the use of deep learning based models in addition to the classical methods. An important difference between classical methods like ARIMA and novel deep learning methods is the following.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/time-series-transformers&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Text-to-Image: Diffusion, Text Conditioning, Guidance, Latent Space</title>
      <link>/post/2022-12-10-text-to-image-diffusion-text-conditioning-guidance-latent-space/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-10-text-to-image-diffusion-text-conditioning-guidance-latent-space/</guid>
      <description>&lt;p&gt;Text-to-image has advanced at a breathless pace in 2021 - 2022, starting with DALL·E, then DALL·E 2, Imagen, and now Stable Diffusion. I dug into a couple of papers to learn more about the space and organized my understanding into a few key concepts&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://eugeneyan.com/writing/text-to-image/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>12 Most Popular NLP Projects of 2022 So Far</title>
      <link>/post/2022-09-25-12-most-popular-nlp-projects-of-2022-so-far/</link>
      <pubDate>Sun, 25 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-09-25-12-most-popular-nlp-projects-of-2022-so-far/</guid>
      <description>&lt;p&gt;Natural Language Processing remains one of the hottest topics of 2022. By using GitHub stars (albeit certainly not the only measure) as a proxy for popularity, we took a look at what NLP projects are getting the most traction so far this year, just as we recently did with machine learning projects. It’s a list with some familiar names but there are plenty of surprises also!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://odsc.com/blog/12-most-popular-nlp-projects-of-2022-so-far/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Skops</title>
      <link>/post/2022-09-03-introducing-skops/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-09-03-introducing-skops/</guid>
      <description>&lt;p&gt;At Hugging Face, we are working on tackling various problems in open-source machine learning, including, hosting models securely and openly, enabling reproducibility, explainability and collaboration. 
We are thrilled to introduce you to our new library: Skops! With Skops, you can host your scikit-learn models on the Hugging Face Hub, create model cards for model documentation and collaborate with others.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/skops&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CS25 I Stanford Seminar</title>
      <link>/post/2022-07-24-cs25-i-stanford-seminar/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-07-24-cs25-i-stanford-seminar/</guid>
      <description>&lt;p&gt;Since their introduction in 2017, transformers have revolutionized Natural Language Processing (NLP). Now, transformers are finding applications all over Deep Learning, be it computer vision (CV), reinforcement learning (RL), Generative Adversarial Networks (GANs), Speech or even Biology. Among other things, transformers have enabled the creation of powerful language models like GPT-3 and were instrumental in DeepMind&amp;rsquo;s recent AlphaFold2, that tackles protein folding.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CS224N: Natural Language Processing with Deep Learning | Winter 2021</title>
      <link>/post/2022-05-02-cs224n-natural-language-processing-with-deep-learning-winter-2021/</link>
      <pubDate>Mon, 02 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-05-02-cs224n-natural-language-processing-with-deep-learning-winter-2021/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugging Face Transformers Amazon SageMaker Examples</title>
      <link>/post/2022-05-02-hugging-face-transformers-amazon-sagemaker-examples/</link>
      <pubDate>Mon, 02 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-05-02-hugging-face-transformers-amazon-sagemaker-examples/</guid>
      <description>&lt;p&gt;Example Jupyter notebooks that demonstrate how to build, train, and deploy Hugging Face Transformers using Amazon SageMaker and the Amazon SageMaker Python SDK.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/huggingface/notebooks/tree/main/sagemaker&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Asking the Right Questions: Training a T5 Transformer Model on a New task</title>
      <link>/post/2022-04-09-asking-the-right-questions-training-a-t5-transformer-model-on-a-new-task/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-asking-the-right-questions-training-a-t5-transformer-model-on-a-new-task/</guid>
      <description>&lt;p&gt;The T5 Transformer frames any NLP task as a text-to-text task enabling pre-trained models to easily learn new tasks. Let’s teach the old dog a new trick!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/asking-the-right-questions-training-a-t5-transformer-model-on-a-new-task-691ebba2d72c&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conversational AI Chatbot with Transformers in Python</title>
      <link>/post/2022-04-09-conversational-ai-chatbot-with-transformers-in-python/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-conversational-ai-chatbot-with-transformers-in-python/</guid>
      <description>&lt;p&gt;Learn how to use Huggingface transformers library to generate conversational responses with the pretrained DialoGPT model in Python.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.thepythoncode.com/article/conversational-ai-chatbot-with-huggingface-transformers-in-python&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conversational Chatbot using Transformers and Streamlit</title>
      <link>/post/2022-04-09-conversational-chatbot-using-transformers-and-streamlit/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-conversational-chatbot-using-transformers-and-streamlit/</guid>
      <description>&lt;p&gt;In this article, we are going to build a Conversational Chatbot app using Transformer (microsoft/DialoGPT-medium model), streamlit.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://chatbotslife.com/conversational-chatbot-using-transformers-and-streamlit-73d621afde9&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two minutes NLP — Quick Introduction to Haystack</title>
      <link>/post/2022-04-09-two-minutes-nlp-quick-introduction-to-haystack/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-two-minutes-nlp-quick-introduction-to-haystack/</guid>
      <description>&lt;p&gt;Question Answering, Semantic Search, and the Retriever-Reader pipeline&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/nlplanet/two-minutes-nlp-quick-introduction-to-haystack-da86d0402998&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/deepset-ai/haystack/issues/486&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deepchecks Suite </title>
      <link>/post/2022-03-21-deepchecks-suite/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-deepchecks-suite/</guid>
      <description>&lt;p&gt;Deepchecks is the leading tool for validating your machine learning models and data, and it enables doing so with minimal effort. Deepchecks accompanies you through various validation needs such as verifying your data’s integrity, inspecting its distributions, validating data splits, evaluating your model and comparing between different models.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.deepchecks.com/en/stable/examples/guides/quickstart_in_5_minutes.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started with Streamlit for NLP</title>
      <link>/post/2022-03-21-getting-started-with-streamlit-for-nlp/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-getting-started-with-streamlit-for-nlp/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/getting-started-with-streamlit-for-nlp-75fe463821ec&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simplifying Transformer Research with xFormers &amp; Lightning</title>
      <link>/post/2022-03-21-simplifying-transformer-research-with-xformers-lightning/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-simplifying-transformer-research-with-xformers-lightning/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://devblog.pytorchlightning.ai/part-i-simplifying-transformer-research-with-xformers-lightning-a715737b8ad4&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual Guide to Transformer Neural Networks</title>
      <link>/post/2022-03-21-visual-guide-to-transformer-neural-networks/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-visual-guide-to-transformer-neural-networks/</guid>
      <description>&lt;p&gt;Visual Guide to Transformer Neural Networks (Series) - Step by Step Intuitive Explanation&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gJ9kaJsE78k&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Flask Web App for Automatic Text Summarization Using SBERT</title>
      <link>/post/2022-02-27-a-flask-web-app-for-automatic-text-summarization-using-sbert/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-02-27-a-flask-web-app-for-automatic-text-summarization-using-sbert/</guid>
      <description>&lt;p&gt;In this blog, we will build a Flask web app that can input any long piece of information such as a blog or news article and summarize it into just five lines!&lt;/p&gt;
&lt;p&gt;Text summarization is an NLP(Natural Language Processing) task. SBERT(Sentence-BERT) has been used to achieve the same.&lt;/p&gt;
&lt;p&gt;By the end of the article, you will learn how to integrate AI models and specifically pre-trained BERT models with Flask web technology as well! I will be explaining the step-by-step implementation right from the setup.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2022/02/a-flask-web-app-for-automatic-text-summarization-using-sbert/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Knowledge Graph for Job Search Using BERT</title>
      <link>/post/2021-12-04-building-a-knowledge-graph-for-job-search-using-bert/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-building-a-knowledge-graph-for-job-search-using-bert/</guid>
      <description>&lt;p&gt;In this tutorial, we will build a job recommendation and skill discovery script that will take unstructured text as input, and will then output job recommendations and skill suggestions based on entities such as skills, years of experience, diploma, and major.&lt;/p&gt;
&lt;p&gt;We will extract entities and relations from job descriptions using the BERT model and we will attempt to build a knowledge graph from skills and years of experience.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/06/knowledge-graph-job-search-bert.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Build a Knowledge Graph with Neo4J and Transformers</title>
      <link>/post/2021-12-04-how-to-build-a-knowledge-graph-with-neo4j-and-transformers/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-how-to-build-a-knowledge-graph-with-neo4j-and-transformers/</guid>
      <description>&lt;p&gt;How to build a knowledge graph from job descriptions using fine-tuned transformer-based Named Entity Recognition (NER) and spacy’s relation extraction models. The method described here can be used in any different field such as biomedical, finance, healthcare, etc.&lt;/p&gt;
&lt;p&gt;Below are the steps we are going to take:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Load our fine-tuned transformer NER and spacy relation extraction model in google colab&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Neo4j Sandbox and add our entities and relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Query our graph to find the highest job match to a target resume, find the three most popular skills and highest skills co-occurrence&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/11/build-knowledge-graph-neo4j-transformers.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Create and Deploy a Simple Sentiment Analysis App via API</title>
      <link>/post/2021-12-04-how-to-create-and-deploy-a-simple-sentiment-analysis-app-via-api/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-how-to-create-and-deploy-a-simple-sentiment-analysis-app-via-api/</guid>
      <description>&lt;p&gt;FastAPI might be able to help. FastAPI is FastAPI is a web framework for building APIs with Python. We will use FastAPI in this article to build a REST API to service an NLP model which can be queried via GET request and can dole out responses to those queries.&lt;/p&gt;
&lt;p&gt;For this example, we will skip the building of our own model, and instead leverage the Pipeline class of the HuggingFace Transformers library. Transformers is full of SOTA NLP models which can be used out of the box as-is, as well as fine-tuned for specific uses and high performance. The library&amp;rsquo;s pipelines can be summed up as:&lt;/p&gt;
&lt;p&gt;The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering.&lt;/p&gt;
&lt;p&gt;Using the Transformers library, FastAPI, and astonishingly little code, we are going to create and deploy a very simple sentiment analysis app. We will also see how extending this same approach to a more complex app would be quite straightforward.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/06/create-deploy-sentiment-analysis-app-api.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Visual Guide to Using BERT for the First Time</title>
      <link>/post/2021-11-14-a-visual-guide-to-using-bert-for-the-first-time/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-11-14-a-visual-guide-to-using-bert-for-the-first-time/</guid>
      <description>&lt;p&gt;This post is a simple tutorial for how to use a variant of BERT to classify sentences.&lt;/p&gt;
&lt;p&gt;This is an example that is basic enough as a first intro, yet advanced enough to showcase some of the key concepts involved.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to fine-tune BERT to classify your Slack chats without coding</title>
      <link>/post/2021-11-14-how-to-fine-tune-bert-to-classify-your-slack-chats-without-coding/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-11-14-how-to-fine-tune-bert-to-classify-your-slack-chats-without-coding/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;images/lifecycle.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Slack chats can become messy with time, proving difficult to extract meaningful information.&lt;/p&gt;
&lt;p&gt;In this article, I want to present a quick codeless way of fine-tuning and deploying the commonly used BERT classifier to do conversational analysis.&lt;/p&gt;
&lt;p&gt;We will use that system to extract tasks, facts, and other valuable information from our Slack conversations.&lt;/p&gt;
&lt;p&gt;It could be easily extended for categorizing any other textual data, like support requests, emails, etc.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/how-to-finetune-bert-to-classify-your-slack-chats-without-coding-3a7002936bcf&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss> 
