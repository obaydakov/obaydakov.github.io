<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>graphs on If you torture the data long enough, it will confess ©</title>
    <link>/tags/graphs/</link>
    <description>Recent content in graphs on If you torture the data long enough, it will confess ©</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Jan 2024 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/graphs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Constructing an Efficient Knowledge Graph RAG Pipeline with LlamaIndex</title>
      <link>/post/2024-01-13-constructing-an-efficient-knowledge-graph-rag-pipeline-with-llamaindex/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-constructing-an-efficient-knowledge-graph-rag-pipeline-with-llamaindex/</guid>
      <description>&lt;p&gt;Retrieval Augmented Generation (RAG) emerges as a solution to bridge this gap, allowing LLMs to access external knowledge sources. This article delves into RAG, examines its elements, and constructs a usable RAG workflow that harnesses the potential of LlamaIndex, a knowledge graph.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ai.gopubby.com/constructing-an-efficient-knowledge-graph-rag-pipeline-with-llamaindex-81a0a0b105b7&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intelligent Graph = Knowledge Graph &#43; Intelligent Agents</title>
      <link>/post/2024-01-13-intelligent-graph-knowledge-graph-intelligent-agents/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-intelligent-graph-knowledge-graph-intelligent-agents/</guid>
      <description>&lt;p&gt;The IntelligentGraph capability is when intelligent agents can be embedded in an RDF graph. These agents are activated only when the graph is queried for results referencing the agent.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@peter.lawrence_47665/intelligent-graph-knowledge-graph-intelligent-agents-b3952399bf8a&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>YouTube Transcripts → Knowledge Graphs for RAG Applications</title>
      <link>/post/2024-01-13-youtube-transcripts-knowledge-graphs-for-rag-applications/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/post/2024-01-13-youtube-transcripts-knowledge-graphs-for-rag-applications/</guid>
      <description>&lt;p&gt;Here we will explore how to scrape YouTube video transcripts into a knowledge graph for Retrieval Augmented Generation (RAG) applications. We will use Google Cloud Platform to store our initial transcripts, LangChain to create documents from the transcripts and a Neo4j graph database to store the resulting documents. In this example we will be creating a knowledge graph containing objective musical facts spoken by Anthony Fantano himself on a select few music genres.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@a-gilmore/youtube-transcripts-knowledge-graphs-for-rag-applications-2cc790543d4b&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Machine Learning Explainability with PyG</title>
      <link>/post/2023-02-04-graph-machine-learning-explainability-with-pyg/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-04-graph-machine-learning-explainability-with-pyg/</guid>
      <description>&lt;p&gt;Graph Neural Networks (GNNs) have become increasingly popular for processing graph-structured data, such as social networks, molecular graphs, and knowledge graphs. However, the complex nature of graph-based data and the non-linear relationships between nodes in a graph can make it difficult to understand why a GNN makes a particular prediction. With the rise in popularity of Graph Neural Networks, there also came an increased interest in explaining their predictions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@pytorch_geometric/graph-machine-learning-explainability-with-pyg-ff13cffc23c2&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph ML in 2023: The State of Affairs</title>
      <link>/post/2023-01-21-graph-ml-in-2023-the-state-of-affairs/</link>
      <pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-21-graph-ml-in-2023-the-state-of-affairs/</guid>
      <description>&lt;p&gt;2022 comes to an end and it is about time to sit down and reflect upon the achievements made in Graph ML as well as to hypothesize about possible breakthroughs in 2023.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/graph-ml-in-2023-the-state-of-affairs-1ba920cb9232&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Graph Machine Learning</title>
      <link>/post/2023-01-21-introduction-to-graph-machine-learning/</link>
      <pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-01-21-introduction-to-graph-machine-learning/</guid>
      <description>&lt;p&gt;We first study what graphs are, why they are used, and how best to represent them. We then cover briefly how people learn on graphs, from pre-neural methods (exploring graph features at the same time) to what are commonly called Graph Neural Networks. Lastly, we peek into the world of Transformers for graphs.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/blog/intro-graphml&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Categories, Graphs, Reasoning</title>
      <link>/post/2022-12-26-categories-graphs-reasoning/</link>
      <pubDate>Mon, 26 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-26-categories-graphs-reasoning/</guid>
      <description>&lt;p&gt;Dr. Petar Veličković  is a Staff Research Scientist at DeepMind, he has firmly established himself as one of the most significant up and coming researchers in the deep learning space. He invented Graph Attention Networks in 2017 and has been a leading light in the field ever since pioneering research in Graph Neural Networks, Geometric Deep Learning and also Neural Algorithmic reasoning. If you haven’t already, you should check out our video on the Geometric Deep learning blueprint, featuring Petar. I caught up with him last week at NeurIPS. In this show, from NeurIPS 2022 we discussed his recent work on category theory and graph neural networks.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=1lkdWduuN14&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pytorch Geometric tutorial</title>
      <link>/post/2022-12-26-pytorch-geometric-tutorial/</link>
      <pubDate>Mon, 26 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-12-26-pytorch-geometric-tutorial/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://antoniolonga.github.io/Pytorch_geometric_tutorials/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using graph neural networks to recommend related products</title>
      <link>/post/2022-11-05-using-graph-neural-networks-to-recommend-related-products/</link>
      <pubDate>Sat, 05 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-11-05-using-graph-neural-networks-to-recommend-related-products/</guid>
      <description>&lt;p&gt;Recommending related products — say, a phone case to go along with a new phone — is a fundamental capability of e-commerce sites, one that saves customers time and leads to more satisfying shopping experiences.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.science/blog/using-graph-neural-networks-to-recommend-related-products&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Neural Network for Recommender System</title>
      <link>/post/2022-10-01-graph-neural-network-for-recommender-system/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-10-01-graph-neural-network-for-recommender-system/</guid>
      <description>&lt;p&gt;Recently, graph neural network (GNN) has become the new state-of-the-art approach in many recommendation problems, with its strong ability to handle structured data and to explore high-order information.	However, as the recommendation tasks are diverse and various in the real world, it is quite challenging to design proper GNN methods for specific problems. In this tutorial, we focus on the critical challenges of GNN-based recommendation and the potential solutions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sites.google.com/view/gnn-recsys&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GraphGPS: Navigating Graph Transformers</title>
      <link>/post/2022-06-26-graphgps-navigating-graph-transformers/</link>
      <pubDate>Sun, 26 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-06-26-graphgps-navigating-graph-transformers/</guid>
      <description>&lt;p&gt;Recipes for cooking the best graph transformers
&lt;a href=&#34;https://towardsdatascience.com/graphgps-navigating-graph-transformers-c2cc223a051c&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Neural Networks: A learning journey since 2008 — Graph Attention Networks</title>
      <link>/post/2022-04-09-graph-neural-networks-a-learning-journey-since-2008-graph-attention-networks/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-04-09-graph-neural-networks-a-learning-journey-since-2008-graph-attention-networks/</guid>
      <description>&lt;p&gt;Today we’ll dive into the theory and implementation of the Graph Attention Network (GAT).
In a nutshell: attention rocks, graphs rock, GAT’s authors rock!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/graph-neural-networks-a-learning-journey-since-2008-graph-attention-networks-f8c39189e7fc&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Neural Networks beyond Weisfeiler-Lehman and vanilla Message Passing</title>
      <link>/post/2022-03-21-graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-03-21-graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing/</guid>
      <description>&lt;p&gt;Physics-inspired continuous learning models on graphs allow to overcome the limitations of traditional GNNs&lt;/p&gt;
&lt;p&gt;The message-passing paradigm has been the “battle horse” of deep learning on graphs for several years, making graph neural networks a big success in a…&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph ML in 2022: Where Are We Now?</title>
      <link>/post/2021-12-30-graph-ml-in-2022-where-are-we-now/</link>
      <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-30-graph-ml-in-2022-where-are-we-now/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/graph-ml-in-2022-where-are-we-now-f7f8242599e0&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KG Course 2021</title>
      <link>/post/2021-12-30-kg-course-2021/</link>
      <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-30-kg-course-2021/</guid>
      <description>&lt;p&gt;Курс по графам знаний (Knowledge Graphs) и как их готовить в 2021 году.
На русском языке.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://migalkin.github.io/kgcourse2021/#syllabus&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyKEEN is a Python package for reproducible, facile knowledge graph embeddings.</title>
      <link>/post/2021-12-30-pykeen-is-a-python-package-for-reproducible-facile-knowledge-graph-embeddings/</link>
      <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-30-pykeen-is-a-python-package-for-reproducible-facile-knowledge-graph-embeddings/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pykeen.readthedocs.io/en/stable/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Knowledge Graph for Job Search Using BERT</title>
      <link>/post/2021-12-04-building-a-knowledge-graph-for-job-search-using-bert/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-building-a-knowledge-graph-for-job-search-using-bert/</guid>
      <description>&lt;p&gt;In this tutorial, we will build a job recommendation and skill discovery script that will take unstructured text as input, and will then output job recommendations and skill suggestions based on entities such as skills, years of experience, diploma, and major.&lt;/p&gt;
&lt;p&gt;We will extract entities and relations from job descriptions using the BERT model and we will attempt to build a knowledge graph from skills and years of experience.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/06/knowledge-graph-job-search-bert.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Machine Learning with Python Part 1: Basics, Metrics, and Algorithms</title>
      <link>/post/2021-12-04-graph-machine-learning-with-python-part-1-basics-metrics-and-algorithms/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-graph-machine-learning-with-python-part-1-basics-metrics-and-algorithms/</guid>
      <description>&lt;p&gt;An introduction to networks via key metrics and algorithms on a Football dataset&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/graph-machine-learning-with-python-pt-1-basics-metrics-and-algorithms-cc40972de113&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Machine Learning with Python Part 2: Random Graphs and Diffusion Models of CryptoPunks Trading</title>
      <link>/post/2021-12-04-graph-machine-learning-with-python-part-2-random-graphs-and-diffusion-models-of-cryptopunks-trading/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-graph-machine-learning-with-python-part-2-random-graphs-and-diffusion-models-of-cryptopunks-trading/</guid>
      <description>&lt;p&gt;Simulating and modeling the CryptoPunks trading data via a graph&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/graph-machine-learning-with-python-pt-2-random-graphs-and-diffusion-models-of-cryptopunks-trading-99cd5170b5ea&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Build a Knowledge Graph with Neo4J and Transformers</title>
      <link>/post/2021-12-04-how-to-build-a-knowledge-graph-with-neo4j-and-transformers/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-how-to-build-a-knowledge-graph-with-neo4j-and-transformers/</guid>
      <description>&lt;p&gt;How to build a knowledge graph from job descriptions using fine-tuned transformer-based Named Entity Recognition (NER) and spacy’s relation extraction models. The method described here can be used in any different field such as biomedical, finance, healthcare, etc.&lt;/p&gt;
&lt;p&gt;Below are the steps we are going to take:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Load our fine-tuned transformer NER and spacy relation extraction model in google colab&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Neo4j Sandbox and add our entities and relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Query our graph to find the highest job match to a target resume, find the three most popular skills and highest skills co-occurrence&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/11/build-knowledge-graph-neo4j-transformers.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Create and Deploy a Simple Sentiment Analysis App via API</title>
      <link>/post/2021-12-04-how-to-create-and-deploy-a-simple-sentiment-analysis-app-via-api/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021-12-04-how-to-create-and-deploy-a-simple-sentiment-analysis-app-via-api/</guid>
      <description>&lt;p&gt;FastAPI might be able to help. FastAPI is FastAPI is a web framework for building APIs with Python. We will use FastAPI in this article to build a REST API to service an NLP model which can be queried via GET request and can dole out responses to those queries.&lt;/p&gt;
&lt;p&gt;For this example, we will skip the building of our own model, and instead leverage the Pipeline class of the HuggingFace Transformers library. Transformers is full of SOTA NLP models which can be used out of the box as-is, as well as fine-tuned for specific uses and high performance. The library&amp;rsquo;s pipelines can be summed up as:&lt;/p&gt;
&lt;p&gt;The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering.&lt;/p&gt;
&lt;p&gt;Using the Transformers library, FastAPI, and astonishingly little code, we are going to create and deploy a very simple sentiment analysis app. We will also see how extending this same approach to a more complex app would be quite straightforward.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/06/create-deploy-sentiment-analysis-app-api.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss> 
